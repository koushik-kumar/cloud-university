# Amazon Simple Storage Service (S3)
Q: How durable is Amazon S3?

Amazon S3 Standard, S3 Standardâ€“IA, S3 One Zone-IA, and S3 Glacier are all designed to provide 99.999999999% durability of objects over a given year.

Standard Storage:
- 99.999999999% durability
- 99.99% availability

Standard-Infrequent Access (S-IA):
- 99.999999999% durability
- 99.9% availability

|Type|Durability|Availability|
|----|----------|------------|
|S3 Standard storage |99.999999999%|99.99%|
|Standard-Infrequent Access (S-IA) storage|99.999999999%|99.9%|
|S3 One Zone-IA storage|99.999999999%|99.5%|

Q: How reliable is Amazon S3?

The **S3 Standard storage** class is designed for 99.99% availability, the **S3 Standard-IA storage** class is designed for 99.9% availability, and the **S3 One Zone-IA storage** class is designed for 99.5% availability. 

https://aws.amazon.com/s3/faqs/

Storage cost:
- Number and size of objets
- Type of storage

Estimate S3 charges:
- Storage Class
- Storage (the number and size of objects stored in your S3 bucket)
- Requests (the number and type of requests)
- Data transfer (the amount of data transferred out of the S3 region)


Q. Which components of the AWS infrastructure can be decsribed as multiple, isolated locations within one geographic area?
- Avaliability Zones

Q. A user has archived data from Amazon S3 to Amazon Glacier. How much data can be restored by the user for free every month?
- 5% of archived data

Q. What are some reasons to enable **cross-region replication** on an Amazon S3 bucket?(Choose 2 answers)
- You have a set of users or customers who can access the second bucket with lower latency.
- For compliance reasons, you need to store data in a location at least 300 miles away from the first region.

Q. You are running a photo sharing website. Users need to be able to retrieve and display any image. On average, most images are requested only once or twice a year. 

Q. What would be the most cost-effective, highly available method of storing the images?
- [x] Save images on Amazon S3 as **Standard-Infrequent Access**
- [] Save images on Amazon S3 as **Glacier Deep Archive**

Q. You are running a photo sharing website with images being served directly from Amazon S3. Users can control whether their photos are public, private or shared amongst nominated friends. How can your application implement these access controls?
- Generate pre-signed URLs for each photo access.

Q. Your company legal team has been advised that some data in Amazon S3 might be required for a pending legal case. You therefore activate **Amazon S3 Object Lock Legal Hold**. When can this object be deleted?
- The object can be deleted by deactivating Legal Hold.

Q. How can you access files stored in Amazon S3 via NFS and SMB from both your data center and Amazon EC2 instances?
1. Install Amazon WorkDocs Sync Client on each machine
2. [x] Mount volumes from [AWS Storage Gateway](https://aws.amazon.com/storagegateway) - File Gateway
3. Use AWS DataSync in replication mode across Direct Connect
4. Use the native file share capabilities of each operating system

Q. You are hosting a massively-multiplayer online game and want to allow customers to download client software whenever a new version is released. What would be the most cost-effective way to distribute this software?
1. [x] Use [Amazon CloudFront Price Class 100](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/PriceClass.html)
2. Use Amazon S3 Auto-Compression option
3. Use Amazon S3 Reduced Redundancy transfer protocol
4. Use [Amazon S3 Transfer Acceleration](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html)

Question: Your company has 17TB of financial trading records that need to be stored for seven years by law. Experience has shown that any record more than a year old is unlikely to be accessed. Which of the following storage plans meets these needs in the most costefficient manner?
- A. Store the data on Amazon Elastic Block Store (Amazon EBS) volume attached to t2.large instances.
- B. Store the data on Amazon Simple Storage Service (Amazon S3) with lifecycle policies that change the storage class to Amazon Glacier after one year, and delete the object after seven years.
- C. Store the data in Amazon DynamoDB, and delete data older than seven years.
- D. Store the data in an Amazon Glacier Vault Lock.

Answer: B. Amazon S3 and Amazon Glacier are the most cost-effective storage services. After a year, when the objects are unlikely to be accessed, you can save costs by transferring the objects to Amazon Glacier where the retrieval time is three to five hours.

Question: What must you do to create a record of who accessed your **Amazon Simple Storage Service (Amazon S3)** data and from where?
- A. Enable Amazon CloudWatch logs.
- B. Enable versioning on the bucket.
- C. Enable website hosting on the bucket.
- D. Enable server access logs on the bucket.
- E. Create an AWS Identity and Access Management (IAM) bucket policy.

Answer: D. Server access logs provide a record of any access to an object in Amazon S3.

Question: Amazon Simple Storage Service (Amazon S3) is an eventually consistent storage system.
For what kinds of operations is it possible to get stale data as a result of eventual
consistency?
- A. GET after PUT of a new object
- B. GET or LIST after a DELETE
- C. GET after overwrite PUT (PUT to an existing key)
- D. DELETE after GET of new object

Answer: C. Amazon S3 provides **read-after-write consistency** for PUTs to new objects (new key), but eventual consistency for GETs and DELETEs of existing objects (existing key). Response C changes the existing object so that a subsequent GET may fetch the previous and inconsistent object.

Question: How is data stored in Amazon Simple Storage Service (Amazon S3) for high durability?
- A. Data is automatically replicated to other regions.
- B. Data is automatically replicated to different Availability Zones within a region.
- C. Data is replicated only if versioning is enabled on the bucket.
- D. Data is automatically backed up on tape and restored if needed.

Answer: B. AWS will never transfer data between regions unless directed to by you. Durability in Amazon S3 is achieved by replicating your data geographically to different Availability Zones regardless of the versioning configuration. AWS doesn't use tapes.

Your company stores critical business documents in Amazon S3, and wants to minimize cost. Most document are used actively for only about a month, then much less frequently. However, all data needs to be available immediately when requested. How can you meet these requirements?
1. Migrate to Amazon S3 Reduced Redundancy Storage (RRS) after 30 days
2. Migrate the data to Amazon Glacier after 30 days
3. Migrate the date to [Amazon S3 Standard - Infrequent Access](https://aws.amazon.com/s3/storage-classes/) after 30 days
4. Turn on versioning, then migrate the older version to Amazon Glacier

Answer: 3. 

## CLI
// Copy MyFile.txt in current directory to s3://my-bucket/path
```
$ aws s3 cp MyFile.txt s3://my-bucket/path/
```
